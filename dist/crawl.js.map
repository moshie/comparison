{"version":3,"file":"crawl.js","sourceRoot":"","sources":["../src/crawl.ts"],"names":[],"mappings":";;AAAA,yBAA0B;AAC1B,kCAAmC;AACnC,oCAAqC;AAIrC,IAAM,KAAK,GAAa,EAAE,CAAA;AAE1B,IAAM,OAAO,GAAa,EAAE,CAAA;AAE5B,uBAAuB,MAAc,EAAE,GAAa,EAAE,MAAe;IAEjE,GAAG,CAAC,CAAC,CAAC,SAAS,CAAC,CAAC,IAAI,CAAC,UAAU,CAAS,EAAE,IAAS;QAEhD,EAAE,CAAC,CAAC,CAAC,IAAI,OAAO,CAAC,CAAC,CAAC;YAEf,MAAM,CAAC,KAAK,CAAC;QACjB,CAAC;QAED,IAAI,IAAI,GAAG,GAAG,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,IAAI,CAAC,MAAM,CAAC,CAAA;QAEnC,IAAI,aAAa,GAAG,IAAI,MAAM,CAAC,wBAAwB,GAAG,MAAM,CAAC,IAAI,GAAG,cAAc,CAAC,CAAA;QACvF,IAAI,YAAY,GAAG,IAAI,MAAM,CAAC,OAAO,CAAC,CAAA;QAEtC,EAAE,CAAC,CAAC,CAAC,aAAa,CAAC,IAAI,CAAC,IAAI,CAAC,IAAI,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;YAC1D,MAAM,CAAC,IAAI,CAAC;QAChB,CAAC;QAED,EAAE,CAAC,CAAC,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC;YAC1B,IAAI,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAA;YACpB,IAAI,IAAI,GAAG,GAAG,CAAC,MAAM,CAAC,MAAM,CAAC,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAA;QACjD,CAAC;QAAC,IAAI,CAAC,CAAC;YACJ,IAAI,IAAI,GAAG,IAAI,CAAA;YACf,IAAI,GAAG,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC,CAAC,QAAQ,CAAA;YAC/B,IAAI,GAAG,OAAO,IAAI,IAAI,QAAQ,IAAI,IAAI,CAAC,MAAM,GAAG,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,GAAG,EAAE,CAAA;QACtE,CAAC;QAED,EAAE,CAAC,CAAC,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC;YAC7B,MAAM,CAAC,IAAI,CAAC;QAChB,CAAC;QAED,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,CAAA;QAEhB,EAAE,CAAC,CAAC,OAAO,CAAC,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,CAAC;YAC9B,OAAO,CAAC,IAAI,CAAC,IAAI,CAAC,CAAC;YACnB,MAAM,CAAC,KAAK,CAAC,IAAI,EAAE,UAAC,GAAa,IAAK,OAAA,aAAa,CAAC,MAAM,EAAE,GAAG,EAAE,MAAM,CAAC,EAAlC,CAAkC,CAAC,CAAA;QAC7E,CAAC;IAEL,CAAC,CAAC,CAAA;AACN,CAAC;AAGD,eAAe,YAAmC;IAC9C,IAAM,GAAG,GAAW,YAAY,CAAC,MAAM,CAAC,IAAI,CAAC,YAAY,CAAC,CAAC,CAAC,CAAC,CAAC,CAAA;IAC9D,IAAM,MAAM,GAAY,GAAG,CAAC,KAAK,CAAC,GAAG,CAAC,CAAA;IAEtC,MAAM,CAAC,IAAI,OAAO,CAAC,UAAC,OAAO,EAAE,MAAM;QAE/B,IAAM,MAAM,GAAW,IAAI,MAAM,CAAC;YAC9B,UAAU,EAAE,CAAC;YACb,KAAK,EAAE,UAAC,KAAU,EAAE,GAAW,IAAK,OAAA,MAAM,CAAC,KAAK,CAAC,EAAb,CAAa;YACjD,IAAI,EAAE,cAAM,OAAA,OAAO,CAAC,KAAK,CAAC,EAAd,CAAc;YAC1B,OAAO,EAAE;gBACL,YAAY,EAAE,0HAA0H;aAC3I;SACJ,CAAC,CAAA;QAEF,MAAM,CAAC,KAAK,CAAC,GAAG,CAAC,MAAM,CAAC,MAAM,CAAC,EAAE,UAAC,GAAa,IAAK,OAAA,aAAa,CAAC,MAAM,EAAE,GAAG,EAAE,MAAM,CAAC,EAAlC,CAAkC,CAAC,CAAA;IAC3F,CAAC,CAAC,CAAA;AAEN,CAAC;AAED,kBAAe,KAAK,CAAA","sourcesContent":["import * as URL from 'url'\nimport * as Promise from 'bluebird'\nimport * as Spider from 'node-spider'\nimport {environmentsInterface} from './environments-interface'\nimport Document from 'node-spider/lib/document'\n\nconst paths: string[] = []\n\nconst visited: string[] = []\n\nfunction handleRequest(spider: Spider, doc: Document, domain: URL.Url) {\n\n    doc.$('a[href]').each(function (i: number, elem: any) {\n        \n        if (i == 1000000) {\n            // Stack overflow prevention\n            return false;\n        }\n\n        let href = doc.$(elem).attr('href')\n\n        let relativeRegex = new RegExp('^(https?\\:\\/\\/(www\\.)?' + domain.host + ')|^(\\/\\w?.*)')\n        let forwardSlash = new RegExp('^(\\/)')\n\n        if (!relativeRegex.test(href) || paths.indexOf(href) !== -1) {\n            return true;\n        }\n\n        if (forwardSlash.test(href)) {\n            href = href.slice(1)\n            var next = URL.format(domain) + href.slice(1)\n        } else {\n            var next = href\n            href = URL.parse(href).pathname\n            href = typeof href == 'string' && href.length ? href.slice(1) : ''\n        }\n\n        if (paths.indexOf(href) !== -1) {\n            return true;\n        }\n\n        paths.push(href)\n        \n        if (visited.indexOf(next) == -1) {\n            visited.push(next);\n            spider.queue(next, (doc: Document) => handleRequest(spider, doc, domain))\n        }\n        \n    })\n}\n\n\nfunction crawl(environments: environmentsInterface): Promise<any> {\n    const url: string = environments[Object.keys(environments)[0]]\n    const domain: URL.Url = URL.parse(url)\n\n    return new Promise((resolve, reject) => {\n        \n        const spider: Spider = new Spider({\n            concurrent: 5,\n            error: (error: any, url: string) => reject(error),\n            done: () => resolve(paths),\n            headers: { \n                'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36' \n            },\n        })\n\n        spider.queue(URL.format(domain), (doc: Document) => handleRequest(spider, doc, domain))\n    })\n\n}\n\nexport default crawl"]}